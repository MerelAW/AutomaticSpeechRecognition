{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to unzip the dataset, which should only be done once! \n",
    "\n",
    "import zipfile\n",
    "zer_ref = zipfile.ZipFile(\"10000_30.zip\", 'r')\n",
    "zer_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "\n",
    "label_csv = pd.read_csv(\"2speakers_10000_30.csv\")\n",
    "names = label_csv[\"Filename\"].tolist()\n",
    "labels = label_csv[\"Speakers\"].tolist()\n",
    "images = []\n",
    "directory = \"./SPECTROGRAMS/\"\n",
    "\n",
    "count = 0\n",
    "for name in names:\n",
    "    name = os.path.splitext(name)[0]\n",
    "    try:\n",
    "        image_array = Image.open(directory+name+\".png\").convert('RGB')\n",
    "        images.append(np.asarray(image_array))\n",
    "    except Exception:\n",
    "        count += 1\n",
    "    \n",
    "if(count > 0):\n",
    "    print(\"Something went wrong!!! Please check it out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.] [2744 3903]\n"
     ]
    }
   ],
   "source": [
    "# This code should only be run once, otherwise it computes categorical labels for the categorical labels!\n",
    "\n",
    "# create data here, split in 3 parts. 0.7 training, 0.2 validation, 0.1 testing is used for large datasets\n",
    "x_train, x_val, x_test = np.split(images, [int(.7*len(labels)), int(.9*len(labels))])\n",
    "y_train, y_val, y_test = np.split(labels, [int(.7*len(labels)), int(.9*len(labels))])\n",
    "\n",
    "# Convert all data to float32 to avoid data type errors\n",
    "x_train = np.float32(x_train)\n",
    "y_train = np.float32(y_train)\n",
    "x_val = np.float32(x_val)\n",
    "y_val = np.float32(y_val)\n",
    "x_test = np.float32(x_test)\n",
    "y_test = np.float32(y_test)\n",
    "\n",
    "# Compute class weights to balance data\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude\n",
    "# Compute weights for all classes!\n",
    "unique, counts = np.unique(y_train, return_counts=True) # only balance train data! \n",
    "print(unique, counts)\n",
    "total = counts[0]+counts[1] # + counts[other classes]\n",
    "weight_for_1 = (1 / counts[0])*(total)/2.0 \n",
    "weight_for_2 = (1 / counts[1])*(total)/2.0\n",
    "class_weight = {1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "# Compute the categorical one-hot encoded labels\n",
    "# Assume three classes instead of two, since the function expects label 0 to be a class as well\n",
    "# Given that the training data only contains labels 1 and 2, the model will not learn to predict label 0 anyway!\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "specshape=(288, 432, 3) # shape of the spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original cifar-10 model as used by \n",
    "# https://towardsdatascience.com/automatic-speaker-recognition-using-transfer-learning-6fab63e34e74\n",
    "\n",
    "def cifar_10():\n",
    "    input_layer = tf.keras.Input(shape=specshape)\n",
    "    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\", padding='same')(input_layer) \n",
    "    conv2 = tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\")(conv1) \n",
    "    max1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    drop1 = tf.keras.layers.Dropout(0.25)(max1) \n",
    "    \n",
    "    conv3 = tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\", padding='same')(drop1) \n",
    "    conv4 = tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\")(conv3) \n",
    "    max2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "    drop2 = tf.keras.layers.Dropout(0.25)(max2) \n",
    "    \n",
    "    flat1 = tf.keras.layers.Flatten()(drop2)\n",
    "    dense1 = tf.keras.layers.Dense(512, activation=\"relu\")(flat1) \n",
    "    drop3 = tf.keras.layers.Dropout(0.5)(dense1) \n",
    "    output_layer = tf.keras.layers.Dense(3, activation=\"softmax\")(drop3) \n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CNN taken from \n",
    "# https://medium.com/x8-the-ai-community/audio-classification-using-cnn-coding-example-f9cbd272269e\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    input_layer = tf.keras.Input(shape=specshape)\n",
    "    conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\")(input_layer) \n",
    "    conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\")(conv1) \n",
    "    max1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    drop1 = tf.keras.layers.Dropout(0.1)(max1) #originally 0.25, but 25% of 64 units is quite a lot\n",
    "    flat1 = tf.keras.layers.Flatten()(drop1)\n",
    "    dense1 = tf.keras.layers.Dense(128, activation=\"relu\")(flat1) #128\n",
    "    drop2 = tf.keras.layers.Dropout(0.2)(dense1) #originally 0.5, but 50% of 128 units is quite a lot \n",
    "    output_layer = tf.keras.layers.Dense(3, activation=\"softmax\")(drop2)\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# Using Adams optimizer with learning rate 0.001\n",
    "# Using categorical crossentropy loss to deal with the one-hot encoded labels\n",
    "# Since there are three labels (0, 1, 2) rather than two (1, 2), binary crossentropy loss cannot be used\n",
    "# Using accuracy as metric\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for reducing the learning rate and stopping training early when the performance drops\n",
    "# Use the validation loss to monitor the performance. \n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=0, min_lr=0.00001)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to plot confusion matrices after every epoch\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "class ConfusionMatrix(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    model = []\n",
    "    \n",
    "    def setup(self, model, validation_x, validation_y):\n",
    "        self.model = model\n",
    "        self.x = validation_x\n",
    "        self.y = validation_y\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Confusion matrix\")\n",
    "        y_prob = self.model.predict(self.x)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        y_true = np.argmax(self.y, axis=1)\n",
    "        print(cm(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the confusion matrix callback with the model and validation data\n",
    "cm_val = ConfusionMatrix()\n",
    "cm_val.setup(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 6647 samples, validate on 1900 samples\n",
      "Epoch 1/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 75.3029 - accuracy: 0.6836Confusion matrix\n",
      "[[592 185]\n",
      " [216 907]]\n",
      "6647/6647 [==============================] - 70s 10ms/sample - loss: 75.2242 - accuracy: 0.6835 - val_loss: 0.4903 - val_accuracy: 0.7889\n",
      "Epoch 2/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.8869Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 65s 10ms/sample - loss: 0.3020 - accuracy: 0.8869 - val_loss: 0.4829 - val_accuracy: 0.7937\n",
      "Epoch 3/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9723Confusion matrix\n",
      "[[621 156]\n",
      " [197 926]]\n",
      "6647/6647 [==============================] - 61s 9ms/sample - loss: 0.0923 - accuracy: 0.9722 - val_loss: 0.5979 - val_accuracy: 0.8142\n",
      "Epoch 4/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9938Confusion matrix\n",
      "[[623 154]\n",
      " [162 961]]\n",
      "6647/6647 [==============================] - 61s 9ms/sample - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.6719 - val_accuracy: 0.8337\n",
      "Epoch 5/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9946Confusion matrix\n",
      "[[622 155]\n",
      " [159 964]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.6835 - val_accuracy: 0.8347\n",
      "Epoch 6/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9956Confusion matrix\n",
      "[[615 162]\n",
      " [150 973]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0194 - accuracy: 0.9956 - val_loss: 0.6773 - val_accuracy: 0.8358\n",
      "Epoch 7/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9965Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.6927 - val_accuracy: 0.8411\n",
      "Epoch 8/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9782Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0858 - accuracy: 0.9782 - val_loss: 0.5085 - val_accuracy: 0.8332\n",
      "Epoch 9/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9792Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0857 - accuracy: 0.9792 - val_loss: 0.5079 - val_accuracy: 0.8316\n",
      "Epoch 10/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9779Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0834 - accuracy: 0.9777 - val_loss: 0.5037 - val_accuracy: 0.8337\n",
      "Epoch 11/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9797Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0812 - accuracy: 0.9797 - val_loss: 0.5131 - val_accuracy: 0.8332\n",
      "Epoch 12/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.9789Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0794 - accuracy: 0.9788 - val_loss: 0.5083 - val_accuracy: 0.8326\n",
      "Epoch 13/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9800Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0805 - accuracy: 0.9798 - val_loss: 0.5095 - val_accuracy: 0.8321\n",
      "Epoch 14/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9788Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0810 - accuracy: 0.9788 - val_loss: 0.5081 - val_accuracy: 0.8321\n",
      "Epoch 15/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9773Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0811 - accuracy: 0.9773 - val_loss: 0.5030 - val_accuracy: 0.8305\n",
      "Epoch 16/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9806Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0781 - accuracy: 0.9804 - val_loss: 0.5166 - val_accuracy: 0.8358\n",
      "Epoch 17/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9789Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0786 - accuracy: 0.9789 - val_loss: 0.5188 - val_accuracy: 0.8358\n",
      "Epoch 18/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 0.9798Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0767 - accuracy: 0.9798 - val_loss: 0.5262 - val_accuracy: 0.8342\n",
      "Epoch 19/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9797Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0755 - accuracy: 0.9797 - val_loss: 0.5329 - val_accuracy: 0.8389\n",
      "Epoch 20/20\n",
      "6640/6647 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9785Confusion matrix\n",
      "[[615 162]\n",
      " [230 893]]\n",
      "6647/6647 [==============================] - 62s 9ms/sample - loss: 0.0762 - accuracy: 0.9785 - val_loss: 0.4957 - val_accuracy: 0.8274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12b7eeb1848>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using a batch size of 16 and a max of 20 epochs\n",
    "# Also use the callbacks and the class weights!\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=20, validation_data=(x_val, y_val), callbacks=[reduce_lr, early_stop, cm_val], class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"asrmodel10000_30_cnn1_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950/950 [==============================] - 3s 3ms/sample - loss: 0.5451 - accuracy: 0.7684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.545062582367345, 0.76842105]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"asrmodel10000_30_cnn1_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the entire test data to obtain the performance per class\n",
    "\n",
    "true_pos = 0 # true label 2 and prediction 2\n",
    "true_neg = 0  # true label 1 and prediction 1\n",
    "false_pos = 0 # true label 1 and prediction 2\n",
    "false_neg = 0 # true label 2 and prediction 1\n",
    "zeros = 0 # just checking if the model ever predicts 0 speakers\n",
    "\n",
    "false_pos_i = []\n",
    "false_neg_i = []\n",
    "zeros_i = []\n",
    "\n",
    "for i in range(950): # 950 is the number of test images!\n",
    "    prediction = model.predict(x_test[i:i+1])[0] \n",
    "    pred = np.argmax(prediction)\n",
    "    true = np.argmax(y_test[i])\n",
    "    if(pred == true and pred == 1):\n",
    "        true_neg += 1\n",
    "    if(pred == true and pred == 2):\n",
    "        true_pos += 1\n",
    "    if(pred != true and pred == 1):\n",
    "        false_neg += 1\n",
    "        false_neg_i.append(i)\n",
    "    if(pred != true and pred == 2):\n",
    "        false_pos += 1\n",
    "        false_pos_i.append(i)\n",
    "    if(pred == 0):\n",
    "        zeros += 1\n",
    "        zeros_i.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual ones: 381\n",
      "correctly predicted ones: 297\n",
      "actual twos: 569\n",
      "correctly predicted twos: 433\n",
      "zero predictions: 0\n"
     ]
    }
   ],
   "source": [
    "# Print the scores computed above\n",
    "\n",
    "print(\"actual ones:\", true_neg + false_pos)\n",
    "print(\"correctly predicted ones:\", true_neg)\n",
    "print(\"actual twos:\", true_pos + false_neg)\n",
    "print(\"correctly predicted twos:\", true_pos)\n",
    "print(\"zero predictions:\", zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8375241779497099\n",
      "0.7609841827768014\n",
      "0.7974217311233887\n"
     ]
    }
   ],
   "source": [
    "precision = true_pos/(true_pos+false_pos)\n",
    "print(precision)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "print(recall)\n",
    "f = (2 * precision * recall) / (precision + recall)\n",
    "print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
